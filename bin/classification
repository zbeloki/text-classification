#!python3

from classification.dataset import Dataset, DatasetSplit
from classification.svm_classifier import SVMClassifier
import classification.utils as utils

import pandas as pd

import argparse
import pdb

def train_svm(args):
    dataset = _load_dataset(args)
    if args.oversample:
        dataset['train'].oversample()
    classifier = SVMClassifier.train(dataset['train'], dataset['dev'], n_trials=args.trials, f_beta=args.f_beta, top_k=args.top_k, n_jobs=args.jobs)
    classifier.save(args.out)

def train_transformer(args):
    pass

def evaluate(args):

    test = DatasetSplit.load(args.test)
    test.binarize_labels()  # @: binarize!
    model = SVMClassifier.load(args.model)
    metrics = model.evaluate(test, args.f_beta, args.top_k)
    print(metrics)

def clean_dataset(args):
    
    ds = DatasetSplit.load(args.tsv, mode=None)
    ds.clean_texts()
    ds.save(args.out)

def lemmatize_dataset(args):

    ds = DatasetSplit.load(args.tsv, mode=None)
    ds.lemmatize(args.hunspell)
    ds.save(args.out)
    
def split_dataset(args):

    names, sizes = _parse_split_args(args)
    ds = DatasetSplit.load(args.tsv, label_column=args.label)
    ds.binarize_labels()
    dataset = ds.split(names, sizes)
    dataset.save(args.out, override=args.force)

def classify(args):
    pass


def _load_dataset(args):

    splits = {
        'train': args.train,
    }
    if args.test is not None:
        splits['test'] = args.test
    if args.dev is not None:
        splits['dev'] = args.dev
        
    dataset = Dataset.load(splits, args.mode)
    for name in ['train', 'test', 'dev']:
        if name not in dataset:
            dataset[name] = None
    return dataset
    
def _parse_split_args(args):

    args = {
        'train': args.train,
        'test': args.test,
        'dev': args.dev,
    }
    non_none_sizes = [ v for v in args.values() if v is not None ]
    if sum(non_none_sizes) > 1.0:
        raise ValueError("Overall size is greater than 1")
    if len(non_none_sizes) == 1:
        raise ValueError("Providing at least two split sizes is required. To use default sizes don't provide any size at all.")
    elif len(non_none_sizes) == 0:
        args['train'], args['test'], args['dev'] = 0.7, 0.15, 0.15
    elif len(non_none_sizes) == 2:
        missing_size = 1.0 - sum(non_none_sizes)
        args = { name: (size if size is not None else missing_size) for name, size in args.items() }
        
    names, sizes = zip(*args.items())
    return names, sizes

if __name__ == '__main__':

    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers(
        dest='action',
        required=True,
        help="Main action")

    # DATASET
    
    parser_dataset = subparsers.add_parser('dataset')
    parser_dataset.add_argument(
        "tsv",
        help="")
    parser_dataset.add_argument(
        "out",
        help="")
    subparsers_dataset = parser_dataset.add_subparsers(
        dest='dataset_action',
        required=True,
        help="")

    parser_dataset_lemmatize = subparsers_dataset.add_parser('lemmatize')
    parser_dataset_lemmatize.add_argument(
        '--hunspell',
        required=True,
        help="")
    parser_dataset_clean = subparsers_dataset.add_parser('clean')
    parser_dataset_split = subparsers_dataset.add_parser('split')
    parser_dataset_split.add_argument(
        '--train',
        type=float,
        help="Relative size of the training set")
    parser_dataset_split.add_argument(
        '--test',
        type=float,
        help="Relative size of the test set")
    parser_dataset_split.add_argument(
        '--dev',
        type=float,
        help="Relative size of the development set")
    parser_dataset_split.add_argument(
        '--label',
        help="Use this column to stratify splits. Required if more than one label-column exist.")
    parser_dataset_split.add_argument(
        '--force',
        action='store_true',
        help="Overwrite dataset split files when exist")

    # TRAIN
    
    parser_train = subparsers.add_parser('train')
    parser_train.add_argument(
        '--train',
        required=True,
        help="Train dataset split")    
    parser_train.add_argument(
        '--test',
        help="Test dataset split")    
    parser_train.add_argument(
        '--dev',
        help="Dev dataset split")    
    parser_train.add_argument(
        '--oversample',
        action='store_true',
        help="Whether to oversample the trainset or not")
    parser_train.add_argument(
        '--mode',
        default='auto',
        help="Classification setting: 'multilabel', 'multiclass', 'auto', None")        
    parser_train.add_argument(
        '--trials',
        type=int,
        default=0,
        help="Number of trials for hyperparameter tuning in addition to the one with default hyperparameters")    
    parser_train.add_argument(
        '--f_beta',
        type=float,
        default=1.0,
        help="The beta value for F{beta}-score, used to evaluate the model")    
    parser_train.add_argument(
        '--top_k',
        action='store_true',
        help="Whether to use top_k or not. It learns top_k as a hyperparameter.")
    parser_train.add_argument(
        "--out",
        required=True,
        help="Output directory to save the model")
    subparsers_train = parser_train.add_subparsers(
        dest='model',
        required=True,
        help="The kind of model train")    
    
    # TRAIN svm

    parser_train_svm = subparsers_train.add_parser('svm')
    parser_train_svm.add_argument(
        '--jobs',
        type=int,
        default=1,
        help="Number of parallel jobs for training")    

    parser_train_trans = subparsers_train.add_parser('transformer')
    
    parser_evaluate = subparsers.add_parser('evaluate')
    parser_evaluate.add_argument(
        '--model',
        required=True,
        help="The pretrained model to evaluate")
    parser_evaluate.add_argument(
        '--test',
        required=True,
        help="The dataset split for testing")
    parser_evaluate.add_argument(
        '--f_beta',
        type=float,
        default=1.0,
        help="Beta value of the F{beta} score")    
    parser_evaluate.add_argument(
        '--top_k',
        type=int,
        help="tok_k value to use when evaluating the model")    

    parser_classify = subparsers.add_parser('classify')

    args = parser.parse_args()

    if args.action == 'dataset':
        if args.dataset_action == 'lemmatize':
            lemmatize_dataset(args)
        elif args.dataset_action == 'clean':
            clean_dataset(args)
        elif args.dataset_action == 'split':
            split_dataset(args)

    elif args.action == 'train':
        if args.model == 'svm':
            train_svm(args)

    elif args.action == 'evaluate':
        evaluate(args)
